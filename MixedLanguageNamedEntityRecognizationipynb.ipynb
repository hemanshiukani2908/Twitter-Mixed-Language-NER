{"cells":[{"cell_type":"code","execution_count":16,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":4315,"status":"ok","timestamp":1739464456724,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"ZNHD816kC1Bt","outputId":"4a0d3849-e127-4a30-d7bf-371febe45e4d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":17,"metadata":{"collapsed":true,"id":"Z4i77qUVlO45","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1739464496296,"user_tz":-330,"elapsed":39574,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"}},"outputId":"cae8a7c1-d1b9-4a96-eb19-3ae314b59170"},"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: nltk in /usr/local/lib/python3.11/dist-packages (3.9.1)\n","Requirement already satisfied: click in /usr/local/lib/python3.11/dist-packages (from nltk) (8.1.8)\n","Requirement already satisfied: joblib in /usr/local/lib/python3.11/dist-packages (from nltk) (1.4.2)\n","Requirement already satisfied: regex>=2021.8.3 in /usr/local/lib/python3.11/dist-packages (from nltk) (2024.11.6)\n","Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from nltk) (4.67.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (2.2.2)\n","Requirement already satisfied: numpy>=1.23.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (1.26.4)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n","Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.5.1+cu124)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.17.0)\n","Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.5)\n","Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2024.9.0)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n","Requirement already satisfied: evaluate in /usr/local/lib/python3.11/dist-packages (0.4.3)\n","Requirement already satisfied: datasets>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.2.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from evaluate) (1.26.4)\n","Requirement already satisfied: dill in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.2.2)\n","Requirement already satisfied: requests>=2.19.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.62.1 in /usr/local/lib/python3.11/dist-packages (from evaluate) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from evaluate) (3.5.0)\n","Requirement already satisfied: multiprocess in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.70.16)\n","Requirement already satisfied: fsspec>=2021.05.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2021.05.0->evaluate) (2024.9.0)\n","Requirement already satisfied: huggingface-hub>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from evaluate) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from evaluate) (24.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.17.0)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (17.0.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (3.11.12)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets>=2.0.0->evaluate) (6.0.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.7.0->evaluate) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.19.0->evaluate) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->evaluate) (2025.1)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets>=2.0.0->evaluate) (1.18.3)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->evaluate) (1.17.0)\n","Requirement already satisfied: datasets in /usr/local/lib/python3.11/dist-packages (3.2.0)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from datasets) (3.17.0)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (1.26.4)\n","Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (17.0.0)\n","Requirement already satisfied: dill<0.3.9,>=0.3.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.3.8)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets) (2.2.2)\n","Requirement already satisfied: requests>=2.32.2 in /usr/local/lib/python3.11/dist-packages (from datasets) (2.32.3)\n","Requirement already satisfied: tqdm>=4.66.3 in /usr/local/lib/python3.11/dist-packages (from datasets) (4.67.1)\n","Requirement already satisfied: xxhash in /usr/local/lib/python3.11/dist-packages (from datasets) (3.5.0)\n","Requirement already satisfied: multiprocess<0.70.17 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.70.16)\n","Requirement already satisfied: fsspec<=2024.9.0,>=2023.1.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<=2024.9.0,>=2023.1.0->datasets) (2024.9.0)\n","Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets) (3.11.12)\n","Requirement already satisfied: huggingface-hub>=0.23.0 in /usr/local/lib/python3.11/dist-packages (from datasets) (0.28.1)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets) (6.0.2)\n","Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (2.4.4)\n","Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.3.2)\n","Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (25.1.0)\n","Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.5.0)\n","Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (6.1.0)\n","Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (0.2.1)\n","Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets) (1.18.3)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.23.0->datasets) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests>=2.32.2->datasets) (2025.1.31)\n","Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2.8.2)\n","Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets) (2025.1)\n","Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets) (1.17.0)\n","Requirement already satisfied: transformers in /usr/local/lib/python3.11/dist-packages (4.48.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers) (3.17.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.24.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.28.1)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers) (2.32.3)\n","Requirement already satisfied: tokenizers<0.22,>=0.21 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.21.0)\n","Requirement already satisfied: safetensors>=0.4.1 in /usr/local/lib/python3.11/dist-packages (from transformers) (0.5.2)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (2024.9.0)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.24.0->transformers) (4.12.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers) (2025.1.31)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.11/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.26.4)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.13.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn) (3.5.0)\n","Requirement already satisfied: accelerate in /usr/local/lib/python3.11/dist-packages (1.3.0)\n","Requirement already satisfied: numpy<3.0.0,>=1.17 in /usr/local/lib/python3.11/dist-packages (from accelerate) (1.26.4)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (24.2)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from accelerate) (5.9.5)\n","Requirement already satisfied: pyyaml in /usr/local/lib/python3.11/dist-packages (from accelerate) (6.0.2)\n","Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (2.5.1+cu124)\n","Requirement already satisfied: huggingface-hub>=0.21.0 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.28.1)\n","Requirement already satisfied: safetensors>=0.4.3 in /usr/local/lib/python3.11/dist-packages (from accelerate) (0.5.2)\n","Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (3.17.0)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2024.9.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (2.32.3)\n","Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.67.1)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub>=0.21.0->accelerate) (4.12.2)\n","Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.4.2)\n","Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.5)\n","Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (9.1.0.70)\n","Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.5.8)\n","Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.2.1.3)\n","Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (10.3.5.147)\n","Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (11.6.1.9)\n","Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.3.1.170)\n","Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (2.21.5)\n","Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (12.4.127)\n","Requirement already satisfied: triton==3.1.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (3.1.0)\n","Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->accelerate) (1.13.1)\n","Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->accelerate) (1.3.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->accelerate) (3.0.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->huggingface-hub>=0.21.0->accelerate) (2025.1.31)\n","Requirement already satisfied: flask in /usr/local/lib/python3.11/dist-packages (3.1.0)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from flask) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from flask) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from flask) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from flask) (1.9.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->flask) (3.0.2)\n","Requirement already satisfied: pyngrok in /usr/local/lib/python3.11/dist-packages (7.2.3)\n","Requirement already satisfied: PyYAML>=5.1 in /usr/local/lib/python3.11/dist-packages (from pyngrok) (6.0.2)\n","Requirement already satisfied: flask-ngrok in /usr/local/lib/python3.11/dist-packages (0.0.25)\n","Requirement already satisfied: Flask>=0.8 in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (3.1.0)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from flask-ngrok) (2.32.3)\n","Requirement already satisfied: Werkzeug>=3.1 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.3)\n","Requirement already satisfied: Jinja2>=3.1.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (3.1.5)\n","Requirement already satisfied: itsdangerous>=2.2 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (2.2.0)\n","Requirement already satisfied: click>=8.1.3 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (8.1.8)\n","Requirement already satisfied: blinker>=1.9 in /usr/local/lib/python3.11/dist-packages (from Flask>=0.8->flask-ngrok) (1.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->flask-ngrok) (2025.1.31)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from Jinja2>=3.1.2->Flask>=0.8->flask-ngrok) (3.0.2)\n"]}],"source":["!pip install nltk\n","!pip install pandas\n","!pip install torch\n","!pip install evaluate\n","!pip install datasets\n","!pip install transformers\n","!pip install scikit-learn\n","!pip install accelerate\n","!pip install flask\n","!pip install pyngrok\n","!pip install flask-ngrok"]},{"cell_type":"code","execution_count":26,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":999,"status":"ok","timestamp":1739466514298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"xFNXgXrUCFDH","outputId":"38f8fdc8-41e1-4397-952e-2cce6e21b87c"},"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Package punkt_tab is already up-to-date!\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":26}],"source":["import re\n","import random\n","import string\n","\n","import pandas as pd\n","import numpy as np\n","\n","import torch\n","from torch.utils.data import Dataset\n","\n","from sklearn.metrics import accuracy_score\n","from sklearn.model_selection import train_test_split\n","\n","from transformers import pipeline\n","from transformers import Trainer\n","from transformers import TrainingArguments\n","from transformers import DataCollatorWithPadding\n","from transformers import BertTokenizer\n","from transformers import BertForSequenceClassification\n","from transformers import AutoModelForSeq2SeqLM, AutoTokenizer\n","from transformers import AutoModelForTokenClassification\n","\n","import nltk\n","from nltk.tokenize import sent_tokenize\n","nltk.download('punkt')\n","nltk.download('punkt_tab')"]},{"cell_type":"code","execution_count":19,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":12,"status":"ok","timestamp":1739464496296,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"bId7VbLcCX5W","outputId":"d77aa462-9094-427a-ef94-069bd4d67655"},"outputs":[{"output_type":"execute_result","data":{"text/plain":["<torch._C.Generator at 0x7b66d3623750>"]},"metadata":{},"execution_count":19}],"source":["random.seed(42)\n","np.random.seed(42)\n","torch.manual_seed(42)"]},{"cell_type":"markdown","metadata":{"id":"SeZB7gxumHSL"},"source":["# **1. Mixed Language Detection**"]},{"cell_type":"code","execution_count":20,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1739464496297,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"byzEXxlIMQNp"},"outputs":[],"source":["# Load the fine-tuned model and tokenizer\n","# lang_detect_model_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/Code-Mixed-mBERT-Fine-Tuned-Language-Detection\"\n","lang_detect_model_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/Code-Mixed-mBERT-Fine-Tuned-Language-Detection-Latest\""]},{"cell_type":"code","execution_count":21,"metadata":{"executionInfo":{"elapsed":11,"status":"ok","timestamp":1739464496297,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"-T8-WW1qrhxQ"},"outputs":[],"source":["def language_detect(sentence):\n","    # Load the model\n","    lang_detect_tokenizer = BertTokenizer.from_pretrained(lang_detect_model_path)\n","    lang_detect_model = BertForSequenceClassification.from_pretrained(lang_detect_model_path, num_labels=5)\n","    # Set the model to evaluation mode\n","    lang_detect_model.eval()\n","    # Tokenize the sentence\n","    inputs = lang_detect_tokenizer(sentence, padding=True, truncation=True, max_length=128, return_tensors=\"pt\")\n","\n","    # Make a prediction\n","    with torch.no_grad():\n","        outputs = lang_detect_model(**inputs)\n","\n","    # Get the predicted label\n","    predicted_class = torch.argmax(outputs.logits, dim=1).item()\n","\n","    # Decode the predicted class (assuming labels represent specific categories)\n","    # Replace with your actual label mapping\n","    label_mapping = {\n","        0: \"Hindi\",\n","        1: \"Marathi\",\n","        2: \"Gujarati\",\n","        3: \"Telugu\",\n","        4: \"English\"\n","    }\n","\n","    decoded_label = label_mapping.get(predicted_class, \"Others\")\n","    print(f\"Language Detection Predicted class: {predicted_class}, Decoded Label: {decoded_label}\")\n","\n","    return decoded_label"]},{"cell_type":"markdown","metadata":{"id":"BlIPmYwW5hyR"},"source":["# **2. Translate the text to Dominant Language**"]},{"cell_type":"code","execution_count":22,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1739464496297,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"hfuV-3hIKcDE"},"outputs":[],"source":["# Loading the model\n","translation_model_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/Language-Detection-NLLB\""]},{"cell_type":"code","execution_count":23,"metadata":{"executionInfo":{"elapsed":10,"status":"ok","timestamp":1739464496297,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"ZcdW3kKP1ITP"},"outputs":[],"source":["language_mapping = {\n","    \"Hindi\": \"hin_Deva\",\n","    \"Marathi\": \"mar_Deva\",\n","    \"Gujarati\": \"guj_Gujr\",\n","    \"Telugu\": \"tel_Telu\",\n","    \"English\": \"eng_Latn\"\n","}\n","\n","def translate_to(paragraph, target_lang=language_mapping['English']):\n","    translation_tokenizer = AutoTokenizer.from_pretrained(translation_model_path)\n","    translation_model = AutoModelForSeq2SeqLM.from_pretrained(translation_model_path)\n","    sentences = sent_tokenize(paragraph)\n","\n","    translated_sentences = []\n","    for sentence in sentences:\n","        inputs = translation_tokenizer(sentence, return_tensors=\"pt\")\n","        # Use tokenizer.convert_tokens_to_ids instead of tokenizer.lang_code_to_id\n","        translated_tokens = translation_model.generate(**inputs, forced_bos_token_id=translation_tokenizer.convert_tokens_to_ids(target_lang))\n","        translated_sentence = translation_tokenizer.batch_decode(translated_tokens, skip_special_tokens=True)[0]\n","        translated_sentences.append(translated_sentence)\n","    return \" \".join(translated_sentences)"]},{"cell_type":"code","execution_count":25,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":443},"executionInfo":{"elapsed":592,"status":"error","timestamp":1739466462357,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"FltkwRDYH1Gj","outputId":"b2fd8fb2-2498-455a-ee3b-4eaa46219c5d"},"outputs":[{"output_type":"error","ename":"OSError","evalue":"Incorrect path_or_model_id: '/content/drive/MyDrive/Colab Notebooks/ner_project/models/Code-Mixed-mBERT-Fine-Tuned-Language-Detection-Latest'. Please provide either the path to a local folder or the repo_id of a model on the Hub.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mHFValidationError\u001b[0m                         Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    402\u001b[0m         \u001b[0;31m# Load from URL or cache if already cached\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 403\u001b[0;31m         resolved_file = hf_hub_download(\n\u001b[0m\u001b[1;32m    404\u001b[0m             \u001b[0mpath_or_repo_id\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36m_inner_fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    105\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0marg_name\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"repo_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"from_id\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"to_id\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 106\u001b[0;31m                 \u001b[0mvalidate_repo_id\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0marg_value\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    107\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_validators.py\u001b[0m in \u001b[0;36mvalidate_repo_id\u001b[0;34m(repo_id)\u001b[0m\n\u001b[1;32m    153\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mrepo_id\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"/\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 154\u001b[0;31m         raise HFValidationError(\n\u001b[0m\u001b[1;32m    155\u001b[0m             \u001b[0;34m\"Repo id must be in the form 'repo_name' or 'namespace/repo_name':\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mHFValidationError\u001b[0m: Repo id must be in the form 'repo_name' or 'namespace/repo_name': '/content/drive/MyDrive/Colab Notebooks/ner_project/models/Code-Mixed-mBERT-Fine-Tuned-Language-Detection-Latest'. Use `repo_type` argument if needed.","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)","\u001b[0;32m<ipython-input-25-c08bc4446e51>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0msentence\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'''Mujhe kal office jaana hai, but I don’t feel like it.'''\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mtarget_language\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlanguage_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mtranslated_sent\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtranslate_to\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlanguage_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlanguage_mapping\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtarget_language\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m<ipython-input-21-aaa056ffd10b>\u001b[0m in \u001b[0;36mlanguage_detect\u001b[0;34m(sentence)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mlanguage_detect\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msentence\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m     \u001b[0;31m# Load the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m     \u001b[0mlang_detect_tokenizer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertTokenizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_detect_model_path\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m     \u001b[0mlang_detect_model\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBertForSequenceClassification\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_pretrained\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlang_detect_model_path\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_labels\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;31m# Set the model to evaluation mode\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/tokenization_utils_base.py\u001b[0m in \u001b[0;36mfrom_pretrained\u001b[0;34m(cls, pretrained_model_name_or_path, cache_dir, force_download, local_files_only, token, revision, trust_remote_code, *init_inputs, **kwargs)\u001b[0m\n\u001b[1;32m   1953\u001b[0m                     \u001b[0;31m# Try to get the tokenizer config to see if there are versioned tokenizer files.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1954\u001b[0m                     \u001b[0mfast_tokenizer_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mFULL_TOKENIZER_FILE\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1955\u001b[0;31m                     resolved_config_file = cached_file(\n\u001b[0m\u001b[1;32m   1956\u001b[0m                         \u001b[0mpretrained_model_name_or_path\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1957\u001b[0m                         \u001b[0mTOKENIZER_CONFIG_FILE\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/transformers/utils/hub.py\u001b[0m in \u001b[0;36mcached_file\u001b[0;34m(path_or_repo_id, filename, cache_dir, force_download, resume_download, proxies, token, revision, local_files_only, subfolder, repo_type, user_agent, _raise_exceptions_for_gated_repo, _raise_exceptions_for_missing_entries, _raise_exceptions_for_connection_errors, _commit_hash, **deprecated_kwargs)\u001b[0m\n\u001b[1;32m    467\u001b[0m         \u001b[0;32mraise\u001b[0m \u001b[0mEnvironmentError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"There was a specific connection error when trying to load {path_or_repo_id}:\\n{err}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    468\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mHFValidationError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 469\u001b[0;31m         raise EnvironmentError(\n\u001b[0m\u001b[1;32m    470\u001b[0m             \u001b[0;34mf\"Incorrect path_or_model_id: '{path_or_repo_id}'. Please provide either the path to a local folder or the repo_id of a model on the Hub.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    471\u001b[0m         ) from e\n","\u001b[0;31mOSError\u001b[0m: Incorrect path_or_model_id: '/content/drive/MyDrive/Colab Notebooks/ner_project/models/Code-Mixed-mBERT-Fine-Tuned-Language-Detection-Latest'. Please provide either the path to a local folder or the repo_id of a model on the Hub."]}],"source":["sentence = '''Mujhe kal office jaana hai, but I don’t feel like it.'''\n","target_language = language_detect(sentence)\n","print(target_language)\n","translated_sent = translate_to(sentence, language_mapping[target_language])\n","print(language_mapping[target_language])\n","print(translated_sent)"]},{"cell_type":"markdown","metadata":{"id":"ZPGFDJ3pvdmd"},"source":["# **3. NER on Predominant translated Text**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1739464496297,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"oM85I7k6NnrX"},"outputs":[],"source":["xlm_based_ner_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/XML-Roberta-Large-Finetuned\"\n","bert_based_ner_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/Bert-Base-Multilingual-Cased-NER-hrl\"\n","fine_tuned_ner_path = \"/content/drive/MyDrive/Colab Notebooks/ner_project/models/IndicBERT-Fine-Tuned/ner_model/checkpoint-3849\""]},{"cell_type":"markdown","metadata":{"id":"1fvsyksSu33a"},"source":["### 1. **Davlan/bert-base-multilingual-cased-ner-hrl**"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"1vvAQuPZPT0C"},"outputs":[],"source":["# Reload the pipeline with the locally saved model\n","def bert_perform_ner_sentence(text):\n","    loaded_tokenizer = AutoTokenizer.from_pretrained(bert_based_ner_path)\n","    loaded_model = AutoModelForTokenClassification.from_pretrained(bert_based_ner_path)\n","    bert_based_ner_pipe = pipeline(\n","        \"ner\",\n","        model=loaded_model,\n","        tokenizer=loaded_tokenizer,\n","        device=0 if torch.cuda.is_available() else -1,\n","        model_kwargs={\"torch_dtype\": torch.float16} if torch.cuda.is_available() else {}\n","    )\n","    entities = bert_based_ner_pipe(text)\n","    formatted_entities = [{\"entity\": e[\"word\"], \"type\": e[\"entity\"]} for e in entities]\n","    return formatted_entities\n","\n","# Example usage\n","translated_sent = \"मुकेश अंबानी रिलायंस इंडस्ट्रीज के अध्यक्ष हैं।\"\n","bert_perform_ner_sentence(translated_sent)"]},{"cell_type":"markdown","metadata":{"id":"4IFglZ5u8rHs"},"source":["### 2. **xlm-roberta-large-finetuned-conll03-english**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"YImpgyzjUBZz"},"outputs":[],"source":["def xlm_perform_ner_sentence(text):\n","    # Load from local directory\n","    loaded_tokenizer = AutoTokenizer.from_pretrained(xlm_based_ner_path)\n","    loaded_model = AutoModelForTokenClassification.from_pretrained(xlm_based_ner_path)\n","    # Reload the pipeline with the locally saved model\n","    ner_pipe = pipeline(\n","        \"ner\",\n","        model=loaded_model,\n","        tokenizer=loaded_tokenizer,\n","        device=0 if torch.cuda.is_available() else -1,\n","        model_kwargs={\"torch_dtype\": torch.float16} if torch.cuda.is_available() else {}\n","    )\n","\n","    # Function to extract named entities\n","    entities = ner_pipe(text)\n","    formatted_entities = [\n","        {\"entity\": e[\"word\"], \"type\": e[\"entity\"]}\n","        for e in entities\n","    ]\n","    return formatted_entities\n","\n","# Example usage\n","translated_sent = \"Elon Musk is the CEO of Tesla and SpaceX.\"\n","xlm_perform_ner_sentence(translated_sent)\n"]},{"cell_type":"markdown","metadata":{"id":"kumnqosio2su"},"source":["### 3. **Fine Tuned IndicBERT**\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"mkDh2oNGUDI0"},"outputs":[],"source":["def group_tokens_by_word(input_text, offsets, word_ids, probs, id2label, uncertainty_threshold=0.5):\n","    grouped = {}\n","    for idx, word_id in enumerate(word_ids):\n","        if word_id is None:\n","            continue  # Skip special tokens\n","        token_offset = offsets[idx]  # [start, end]\n","        token_prob = probs[idx]      # probability vector for this token\n","        if word_id not in grouped:\n","            grouped[word_id] = {\n","                \"start\": token_offset[0],\n","                \"end\": token_offset[1],\n","                \"probs\": [token_prob],\n","                \"token_indices\": [idx]\n","            }\n","        else:\n","            grouped[word_id][\"start\"] = min(grouped[word_id][\"start\"], token_offset[0])\n","            grouped[word_id][\"end\"] = max(grouped[word_id][\"end\"], token_offset[1])\n","            grouped[word_id][\"probs\"].append(token_prob)\n","            grouped[word_id][\"token_indices\"].append(idx)\n","\n","    word_groups = []\n","    for word_id in sorted(grouped.keys()):\n","        group = grouped[word_id]\n","        group_probs = torch.stack(group[\"probs\"], dim=0)  # shape: (n_tokens, num_labels)\n","        avg_prob = torch.mean(group_probs, dim=0)          # shape: (num_labels,)\n","        max_prob, label_idx = torch.max(avg_prob, dim=0)\n","        chosen_label = id2label[label_idx.item()]\n","        # Fallback: if maximum probability is below the threshold, mark as \"O\"\n","        if max_prob.item() < uncertainty_threshold:\n","            chosen_label = \"O\"\n","        word_groups.append({\n","            \"word_id\": word_id,\n","            \"start\": group[\"start\"],\n","            \"end\": group[\"end\"],\n","            \"avg_prob\": avg_prob,\n","            \"label\": chosen_label,\n","            \"token_indices\": group[\"token_indices\"]\n","        })\n","    return word_groups\n","\n","def postprocess_labels(word_groups):\n","    final_labels = []\n","    for i, group in enumerate(word_groups):\n","        label = group[\"label\"]\n","        # If the label is not \"O\", check previous label for continuity.\n","        if i > 0 and label != \"O\" and final_labels[-1] != \"O\":\n","            prev_entity = final_labels[-1].split(\"-\")[-1]\n","            curr_entity = label.split(\"-\")[-1]\n","            if prev_entity == curr_entity:\n","                # Force the current label to be I-<entity>\n","                label = \"I-\" + curr_entity\n","            else:\n","                # Otherwise, if current label starts with I- without continuity, force it to B-\n","                if label.startswith(\"I-\"):\n","                    label = \"B-\" + curr_entity\n","        # Also, if the very first label is I- something, change it to B-\n","        if i == 0 and label.startswith(\"I-\"):\n","            label = \"B-\" + label[2:]\n","        final_labels.append(label)\n","    return final_labels\n","\n","def reconstruct_words(input_text, word_groups):\n","    words = []\n","    for group in word_groups:\n","        word_text = input_text[group[\"start\"]:group[\"end\"]]\n","        # Optionally, strip extraneous quotes or spaces.\n","        word_text = word_text.strip(' \"')\n","        words.append(word_text)\n","    return words\n","\n","\n","def bert_finetuned_perform_ner_sentence(input_text):\n","    # Step 2: Load the tokenizer and model\n","    tokenizer = AutoTokenizer.from_pretrained(fine_tuned_ner_path)\n","    model = AutoModelForTokenClassification.from_pretrained(fine_tuned_ner_path, local_files_only=True)\n","\n","    # Step 3: Define label mapping\n","    id2label = {\n","        0: \"O\", 1: \"B-PER\", 2: \"I-PER\", 3: \"B-ORG\", 4: \"I-ORG\",\n","        5: \"B-LOC\", 6: \"I-LOC\", 7: \"B-EVT\", 8: \"I-EVT\",\n","        9: \"B-PROD\", 10: \"I-PROD\"\n","    }\n","\n","    # Step 5: Tokenize the raw text with offset mappings and word_ids.\n","    # Do NOT pre-split the text.\n","    inputs = tokenizer(\n","        input_text,\n","        return_tensors=\"pt\",\n","        truncation=True,\n","        padding=True,\n","        return_offsets_mapping=True  # returns offsets for each token\n","    )\n","    # Extract offset mappings and word_ids from the fast tokenizer.\n","    offsets = inputs.pop(\"offset_mapping\")[0].tolist()  # List of [start, end] pairs.\n","    word_ids = inputs.word_ids(batch_index=0)            # Maps each token to its originating word (or None).\n","\n","    # Step 6: Perform prediction and compute probabilities.\n","    with torch.no_grad():\n","        outputs = model(**inputs)\n","    logits = outputs.logits[0]  # shape: (seq_len, num_labels)\n","    probs = torch.softmax(logits, dim=1)  # shape: (seq_len, num_labels)\n","\n","    # Step 7: Group tokens by word.\n","    word_groups = group_tokens_by_word(input_text, offsets, word_ids, probs, id2label, uncertainty_threshold=0.5)\n","    # print(word_groups)\n","\n","    # Reconstruct words exactly as in the original input.\n","    final_words = reconstruct_words(input_text, word_groups)\n","\n","    # Get initial labels from each group.\n","    initial_labels = [group[\"label\"] for group in word_groups]\n","\n","    # Step 8: Post-process labels to enforce continuity and apply uncertainty fallback.\n","    final_labels = postprocess_labels(word_groups)\n","    formatted_entities = [{\"entity\": e, \"type\": l} for e, l in zip(final_words, final_labels)]\n","    return formatted_entities\n","\n","translated_sent = \"मुकेश अंबानी रिलायंस इंडस्ट्रीज के अध्यक्ष हैं।\"\n","bert_finetuned_perform_ner_sentence(translated_sent)"]},{"cell_type":"markdown","metadata":{"id":"f2jbz5263nq8"},"source":["# **4. Clubing all pieces together**"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":9,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"bgmt41_oBUp3"},"outputs":[],"source":["!ngrok config add-authtoken 2sofHDQPwfl8epeBRJE23u8zYUm_7tnntmjd6Xngc6G1d7uxW"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"_HfvhDGLtA2r"},"outputs":[],"source":["!mkdir ./templates"]},{"cell_type":"code","execution_count":null,"metadata":{"executionInfo":{"elapsed":8,"status":"aborted","timestamp":1739464496298,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"},"user_tz":-330},"id":"rmOL56TuDx-k"},"outputs":[],"source":["!cp /content/drive/MyDrive/Colab\\ Notebooks/ner_project/templates/index.html ./templates/"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"M0Ocgob3AaKH","executionInfo":{"status":"aborted","timestamp":1739464496298,"user_tz":-330,"elapsed":8,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"}}},"outputs":[],"source":["import time\n","import requests\n","from flask import Flask, request, jsonify, render_template\n","from pyngrok import ngrok\n","\n","# Initialize Flask app\n","app = Flask(__name__)\n","\n","def detect_language(text):\n","    res = language_detect(text)\n","    print(res)\n","    languages = [\"english\", \"hindi\", \"marathi\", \"telugu\", \"gujarati\"]\n","    return res if res.lower() in languages else \"others\"\n","\n","\n","def perform_ner(text, model_choice):\n","    if model_choice == \"BERT Base Model\":\n","        return bert_perform_ner_sentence(text)\n","    elif model_choice == \"XLM-R Model\":\n","        return xlm_perform_ner_sentence(text)\n","    elif model_choice == \"Fine-Tuned BERT Model\":\n","        return bert_finetuned_perform_ner_sentence(text)\n","    else:\n","        return []\n","\n","@app.route('/')\n","def index():\n","    return render_template('index.html')\n","\n","@app.route('/process', methods=['POST'])\n","def process_text():\n","    data = request.get_json()\n","    text = data.get(\"text\", \"\").strip()\n","    model_choice = data.get(\"model_choice\", \"Fine-Tuned BERT Model\")  # Default model\n","\n","    if not text:\n","        return jsonify({\n","            \"detected_language\": \"Error\",\n","            \"translated_text\": \"Error: Empty input\",\n","            \"ner_results\": []\n","        })\n","\n","    detected_lang = detect_language(text)\n","\n","    if detected_lang == \"others\":\n","        return jsonify({\n","            \"detected_language\": \"Others\",\n","            \"translated_text\": \"Not supported\",\n","            \"ner_results\": []\n","        })\n","\n","    translated_text = translate_to(text, language_mapping[detected_lang])\n","    ner_results = perform_ner(translated_text, model_choice)  # Call function based on model selection\n","\n","    return jsonify({\n","        \"detected_language\": detected_lang,\n","        \"translated_text\": translated_text,\n","        \"ner_results\": ner_results\n","    })\n","\n","# Start the Flask app and expose it using ngrok\n","if __name__ == '__main__':\n","    public_url = ngrok.connect(5000).public_url\n","    print(f\"Public URL: {public_url}\")\n","    app.run(port=5000)\n","\n"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"k4SALpe8CtxZ","executionInfo":{"status":"aborted","timestamp":1739464496298,"user_tz":-330,"elapsed":8,"user":{"displayName":"Severus Snape","userId":"05470723116012730712"}}},"outputs":[],"source":["ngrok.kill()\n","ngrok.disconnect(public_url)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}